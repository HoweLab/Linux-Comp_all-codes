{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script for running our caiman analysis function on 2P data</h1>\n",
    "<h3>A couple of things to note: </h3>\n",
    "<ul>\n",
    "  <li>Make sure that caiman is your active anaconda environment. It should say caiman (Python 3/10/9) in the top right of your VS Code notebook.</li>\n",
    "  <li>If caiman is not active you can type \"conda activate caiman\" into the VS Code terminal at the bottom of your screen.</li>\n",
    "  <li>If for some reason the script throws an error, please restart the notebook before trying to run it again.</li>\n",
    "  <li>You can get paths easily on windows with shift + right click -> copy as path or on linux by dragging the file into an empty terminal and copying the resulting string.</li>\n",
    "  <li>File paths on windows will need an r before the path r\"myFilePath\", on linux this is not necessary.</li>\n",
    "  <li>You can run any cell in this notebook by either clicking the play button next to the cell, or selecting the cell and pressing ctrl + enter</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 15:52:31.265735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of movies to process:  [['/home/howelab/Desktop/testData/test071624/ConcatenatedMovie_MC_CROP.tif']]\n",
      "Defining parameters...\n",
      "Starting CNMF...\n",
      "Starting component evaluation....\n",
      "USING MODEL (keras API): /home/howelab/caiman_data/model/cnn_model.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 15:54:49.066544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step\n",
      "CNMF Finished, saving images...\n",
      "Time taken:3.1333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s].60s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Importing functions from other files for use in this script\n",
    "#Note that these files must be in the same directory as your script in order to import them like this\n",
    "from mainCaimanFunction import runCaimanPipeline\n",
    "from findDict import getCaimanParams\n",
    "from tifLookup import findMovs\n",
    "\n",
    "#assemble a list of your movies: Either create the list manually or have some function do it for you. \n",
    "#The library os with the path module (os.path) will be very usefulf for directory manipulation\n",
    "# movieList = [r\"G:\\TdTG7_18_025\\field1_track\\ConcatenatedMovie_MC_reg.tif\", r\"D:\\Ben 2P Cell Segmentation Data\\Brenna Data\\TdTG7_7_019\\TdTG7_7_019_001_ch1_MC_reg.tif\"]\n",
    "#note that you need to put an r before your string (outside of the quotes) because python needs to convert the windows path to something that it can read (only need this on windows)\n",
    "\n",
    "#You can use this function if your folder follows the pattern of mainFolder -> field folders -> videos inside each field folder\n",
    "#just specify the pattern that you want the function to look for in these sub folders\n",
    "# movieList = findMovs([r\"G:\\TdTG7_18_025\", r\"G:\\TdTG7_18_026\", r\"G:\\TdTG7_18_027\"], 'mc_reg.tif') #-> This will return the list in the proper format, don't worry about\n",
    "#formatting into a list inside a list\n",
    "\n",
    "movieList = [\"/home/howelab/Desktop/testData/test071624/ConcatenatedMovie_MC_CROP.tif\"]\n",
    "\n",
    "\n",
    "#Note that the internal caiman functions wants a list for each movie that you want to run. Therefore when you assemble your list make sure they are lists INSIDE of lists.\n",
    "#If you need to do this (not using the findMovs function) below is an example of how to do that in python.\n",
    "\n",
    "assembledList = []\n",
    "for movie in movieList:\n",
    "    assembledList.append([movie]) \n",
    "# assmebledList = [['Example.tif], ['Example2.tif']] -> Here each movie is in its own list inside the outer list\n",
    "print(\"List of movies to process: \", assembledList)\n",
    "\n",
    "# just loop over our assembledList and grab whichever dictionary we want, and pass that and our current fname in to the runCaimanPipeline function.\n",
    "for cT in range(len(assembledList)):\n",
    "    fnames = assembledList[cT]  # filename to be processed\n",
    "    #note that the only required input is fnames. Give the optional input of 'brenna20' or 'gabi20' to switch between the two different param dictionaries\n",
    "    paramDict = getCaimanParams(fnames, 'brenna20')\n",
    "\n",
    "    #There are optional inputs here if you do not want to save out images of what your components look like, and if you want to save out both your bad good and bad components.\n",
    "    # caimanResult = runCaimanPipeline(fnames, paramDict, selectComponents = False, saveImages = False) -> by default select components is on, and save images is on. This is how you change them\n",
    "    caimanResult = runCaimanPipeline(fnames, paramDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mainCaimanFunction import runCaimanPipeline\n",
    "from findDict import getCaimanParams\n",
    "\n",
    " # filename to be processed\n",
    "fnames = [r\"D:\\Ben 2P Cell Segmentation Data\\GabiData\\20x\\GR_20XSample.tif\"]\n",
    "\n",
    "#I have also built in the ability to choose your dictionary and change any of the parameters that you wish as optional inputs.\n",
    "#You can change any of the following parameters if you wish:\n",
    "\n",
    "# brennaParams20x = {\n",
    "# 'fnames': fnames,\n",
    "#             'fr': 31,\n",
    "#             'decay_time': 0.3,\n",
    "#             'p': 2,\n",
    "#             'nb': 2,\n",
    "#             'rf': 24,\n",
    "#             'K': 4, \n",
    "#             'gSig': [4,4],\n",
    "#             'stride': 8,\n",
    "#             'method_init': 'greedy_roi',\n",
    "#             'rolling_sum': True,\n",
    "#             'only_init': True,\n",
    "#             'ssub': 2,\n",
    "#             'tsub': 2,\n",
    "#             'merge_thr': 0.60, \n",
    "#             'min_SNR': 2.0,\n",
    "#             'rval_thr': 0.80,\n",
    "#             'use_cnn': True,\n",
    "#             'min_cnn_thr': 0.90,\n",
    "#             'cnn_lowest': 0.30}\n",
    "\n",
    "#Below is an example of how to use these optional key arguments. Just make sure you use the exact name of the key in the dictionary.\n",
    "#Example: I want to change the number of components (K) you would call the function like thhis: paramDict = getCaimanParams(fnames, 'gabi20', userInput = True, K = 6)\n",
    "#Note that the key argument K is not input as a string but instead as an assignment statement.\n",
    "paramDict = getCaimanParams(fnames, 'gabi20', userInput = True, K = 6, ssub = 1, tsub = 1, cnn_lowest = 0.45)\n",
    "#Now you can just pass that assembled parameter dictionary into the pipeline function. \n",
    "caimanResult = runCaimanPipeline(fnames, paramDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c7d5f664bc7ed57bde1e5dbd9f7ff61bc675706c7fa377e108b68525ddcc7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
